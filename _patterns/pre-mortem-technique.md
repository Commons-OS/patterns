---
# ═══════════════════════════════════════════════════════════════════
# GROUP 1: CORE IDENTITY
# ═══════════════════════════════════════════════════════════════════
id: pat_01khvcxdwpf7kbp9a3hdn6r4re
slug: pre-mortem-technique
title: "Pre-Mortem Technique for Anticipating Failure"
aliases: []
summary: >-
  Pre-mortem (imagining a project failed and working backward to causes)
  reveals risks that conventional planning misses. This technique
  harnesses negative imagination constructively.

# ═══════════════════════════════════════════════════════════════════
# GROUP 2: CONTEXTUAL TRANSLATION (The Navigator Engine)
# ═══════════════════════════════════════════════════════════════════
context_labels:
  corporate: "Pre-Mortem Technique for Anticipating Failure for Organizations"
  government: "Pre-Mortem Technique for Anticipating Failure in Public Service"
  activist: "Pre-Mortem Technique for Anticipating Failure for Movements"
  tech: "Pre-Mortem Technique for Anticipating Failure for Products"

# ═══════════════════════════════════════════════════════════════════
# GROUP 3: ONTOLOGY & SEARCH OPTIMIZATION (The RAG Fuel)
# ═══════════════════════════════════════════════════════════════════
ontology:
  domain: ethical-reasoning
  cross_domains: []
  commons_domain:
    - life
  search_hints:
    primary_tension: "Pre vs. Failure"
    vector_keywords: ["pre mortem", "technique", "anticipating", "failure", "imagining"]
  commons_assessment:
    stakeholder_architecture: 3.0
    value_creation: 3.5
    resilience: 3.0
    ownership: 3.0
    autonomy: 3.0
    composability: 3.0
    fractal_value: 4.0
    vitality: 3.5
    vitality_reasoning: >-
      This pattern sustains vitality by maintaining and renewing the
      system's existing health. 'Pre-Mortem Technique for Anticipating
      Failure' contributes to ongoing functioning without necessarily
      generating new adaptive capacity. Watch for signs of rigidity if
      implementation becomes routinised.
    overall_score: 3.2

# ═══════════════════════════════════════════════════════════════════
# GROUP 4: LIFECYCLE & CONFIDENCE
# ═══════════════════════════════════════════════════════════════════
lifecycle:
  usage_stage: application
  adoption_stage: growth
  status: draft
  version: 0.1
  confidence: 1

# ═══════════════════════════════════════════════════════════════════
# GROUP 5: HARD RELATIONSHIPS (Human-Curated Graph)
# ═══════════════════════════════════════════════════════════════════
relationships:
  generalizes_from: []
  specializes_to: []
  enables:
    - slug: adaptive-strategy-under-uncertainty
      weight: 0.85
    - slug: adaptive-action-in-complex-systems
      weight: 0.82
  requires: []
  alternatives:
    - slug: active-imagination-technique
      weight: 0.72
  complementary:
    - slug: acting-despite-irreducible-uncertainty
      weight: 0.85
    - slug: adversity-quotient
      weight: 0.82
    - slug: adversarial-growth
      weight: 0.8
  tools: []
# ═══════════════════════════════════════════════════════════════════
# GROUP 6: GRAPH GARDEN (Machine-Written Graph)
# ═══════════════════════════════════════════════════════════════════
graph_garden:
  last_pruned: 2026-02-19
  entities:
    - id: gary-klein
      type: person
      label: "Gary Klein"
      relevance: 0.85
    - id: negative-imagination
      type: concept
      label: "Negative Imagination"
      relevance: 0.9
    - id: risk-identification
      type: practice
      label: "Risk Identification"
      relevance: 0.95
    - id: prospective-hindsight
      type: concept
      label: "Prospective Hindsight"
      relevance: 0.9
    - id: project-planning
      type: practice
      label: "Project Planning"
      relevance: 0.85
    - id: failure-analysis
      type: practice
      label: "Failure Analysis"
      relevance: 0.88
    - id: cognitive-bias-mitigation
      type: concept
      label: "Cognitive Bias Mitigation"
      relevance: 0.82
    - id: scenario-planning
      type: practice
      label: "Scenario Planning"
      relevance: 0.8
  communities:
    - id: futures-planning-strategy
      label: "Futures Planning & Strategy"
      source: taxonomy
      confidence: 0.95
    - id: decision-making-cognition
      label: "Decision-Making & Cognition"
      source: taxonomy
      confidence: 0.9
    - id: risk-management
      label: "Risk Management"
      source: inferred
      confidence: 0.88
    - id: adaptive-leadership
      label: "Adaptive Leadership"
      source: inferred
      confidence: 0.8
  inferred_links:
    - target: adaptive-strategy-under-uncertainty
      type: complementary
      confidence: 0.88
      reason: "Pre-mortem reveals hidden risks; adaptive strategy manages revealed uncertainties."
    - target: acting-despite-irreducible-uncertainty
      type: complementary
      confidence: 0.85
      reason: "Pre-mortem surfaces uncertainties before decisive action is required."
    - target: adaptive-action-in-complex-systems
      type: enables
      confidence: 0.83
      reason: "Sensing and analyzing phase benefits from pre-mortem's structured risk revelation."
    - target: adversity-quotient
      type: complementary
      confidence: 0.78
      reason: "Pre-mortem prepares psychological capacity to handle anticipated adversities."
    - target: adversarial-growth
      type: complementary
      confidence: 0.75
      reason: "Pre-mortem engagement with difficulty builds adaptive capacity through imagination."
    - target: accountability-partnership
      type: tools
      confidence: 0.73
      reason: "Pairs can conduct pre-mortems together to surface risks accountably."
    - target: active-imagination-technique
      type: alternatives
      confidence: 0.72
      reason: "Both use imaginative engagement but pre-mortem is future-focused and structured."
# ═══════════════════════════════════════════════════════════════════
# GROUP 7: PROVENANCE
# ═══════════════════════════════════════════════════════════════════
contributors: ["higgerix", "cloudsters"]
sources:
  - "Risk Assessment"
license: CC-BY-SA-4.0
attribution: "commons.engineering by cloudsters, https://cloudsters.net"
---

Pre-mortem harnesses negative imagination constructively to surface risks that conventional planning consistently misses.

> [!NOTE] Confidence Rating: ★★★ (Established)
> This pattern draws on Risk Assessment.

---

### Section 1: Context

The systems most vulnerable to catastrophic failure are those that mistake confidence for robustness. In organizations, public agencies, movements, and product teams, planning cycles typically focus on what *should* happen: roadmaps, timelines, resource allocations. This forward-facing orientation has real utility—it coordinates effort and allocates attention. But it creates a blind spot: the intelligent people closest to the work often hold unspoken concerns, half-formed doubts, pattern recognition from past failures that never surface in formal risk registers.

The living ecosystem here is one of asymmetric information. Frontline practitioners, engineers, community organizers, and field staff perceive vulnerability patterns—organizational brittleness, technical debt, coalition fragility—that don't fit neatly into spreadsheets. Meanwhile, decision-makers operate with sanitized summaries. The system grows brittle not from lack of data, but from the absence of psychological permission to voice "what could go wrong" without triggering defensiveness or blame.

Pre-mortem technique addresses this state. It creates a bounded container where pessimism becomes a collective strength rather than an individual liability. The pattern is especially vital in commons contexts, where distributed ownership means no single person holds complete sight lines, and where trust erosion from unaddressed concerns can fragment co-stewardship quickly.

---

### Section 2: Problem

> **The core conflict is Pre vs. Failure.**

Conventional planning assumes we can predict and prevent failure by analyzing what we know now. This *Pre* stance—rigorous forecasting, scenario planning, risk matrices—creates order and confidence. It makes sense to sponsors and stakeholders.

Yet failure emerges from what we *don't* know we don't know. The tensions that surface only under stress. The single points of dependency no one explicitly named. The governance gaps that appear when coordination breaks. The cultural assumptions that evaporate when incentives shift. These are *Failure* knowledge: patterns that only reveal themselves through imagining collapse.

The unresolved tension produces three breakdown patterns:

**Silent risk accumulation**: Team members notice warning signs—a key person is burning out, a critical dependency is fragile, a power dynamic is becoming extractive—but lack psychological safety to name it. The risks compound invisibly until crisis hits.

**Legitimacy of late-stage concerns**: When problems emerge mid-project, the people who raise them are often cast as obstructive or lacking confidence, rather than as stewards flagging real vulnerability. By then, course correction is costly.

**Ownership paralysis**: In co-stewarded systems, unspoken concerns about failure modes can create passive-aggressive withdrawal. People stop investing energy if they don't believe in the vessel's viability, but never voice why. The system weakens from within.

Pre-mortem technique resolves this by making failure imagination *legitimate and scheduled*—not a deviation from proper planning, but an essential complement to it.

---

### Section 3: Solution

> **Therefore, conduct a structured collective imagination exercise where participants imagine the initiative has failed completely, then work backward to identify the causal chains that produced that collapse.**

Pre-mortem operates by flipping the temporal arrow. Instead of asking "what could go wrong," it asks "what *did* go wrong?" This grammatical shift is neurocognitively significant. Speaking about failure as past fact (rather than hypothetical risk) reduces defensive reasoning and social anxiety. The imagination becomes investigative rather than accusatory.

The mechanism works like this: The group converges at a midpoint or endpoint in the initiative's arc. Someone names a specific failure scenario—the initiative stalled, resources dried up, key coalition members left, the intended beneficiaries rejected the approach, or the commons fractured into competing camps. Everyone accepts this as *already happened*.

From that imagined collapse, participants work backward as if conducting a post-mortem: What sequence of events, decisions, or unaddressed tensions produced this outcome? The backward-working motion is crucial. It short-circuits the defensive rehearsal of "here's why my domain is fine." Instead, people trace causal chains: "If we ended up here, then *this* must have been true earlier, and *before that*, something else must have been true."

This becomes root-cause imagination rather than blame-seeking. The psychological safety is higher because no one is confessing to current failure—they're cooperatively solving a puzzle about something already gone.

In living systems terms, pre-mortem surfaces the latent tensions and brittleness points before they become stress fractures. It reveals where the commons is overreliant on unstated goodwill, single individuals, or assumptions that haven't been stress-tested. The pattern doesn't prevent failure, but it radically improves the signal-to-noise ratio of what matters to attend to *now*.

---

### Section 4: Implementation

**Convene at a moment of momentum, not crisis.** Schedule the pre-mortem when the initiative is functioning adequately—past initial setup, before critical irreversibility. Trying to surface risks when the system is already failing becomes defensive. Choose a moment when people have enough psychological safety to imagine disappointment.

**Frame it explicitly as imagination, not prediction.** Open with: "We're going to imagine this initiative failed completely. This is not a vote of no confidence. It's a diagnostic. We're borrowing from surgery—a pre-mortem reveals what a post-mortem would find, except we get to act on it."

**Name a specific, vivid failure scenario.** Not "things didn't work out," but concrete: "It's 18 months from now. The coalition fractured. The funding source withdrew. The beneficiary communities felt unheard and stopped participating." Make it specific enough that people can *see* it. This prevents abstraction-creep.

**Create strict psychological safety boundaries.** This exercise only works if participants believe their naming of failure patterns won't be used against them later or treated as self-sabotage. One co-steward can name, "Whatever surfaces here is diagnostic, not predictive. No one will be blamed for identifying a risk." Then hold that boundary ruthlessly.

**In corporate contexts**: Run the pre-mortem with the full delivery team, not just leadership. A product team pre-mortem might imagine: "The adoption never gained traction. Customers preferred the competitor. We burned through runway." Working backward from that, the team names: "We never validated the core assumption about customer workflow integration." That surfaces a test to run *now*, before you've locked in architecture.

**In government/public service**: The pre-mortem reveals how policy fails in implementation, not in theory. Imagine the program is underfunded, staff burned out, and target communities circumvented the system. Working backward surfaces: "We never built feedback loops with frontline workers," or "Eligibility rules created perverse incentives." Those become redesign targets before launch.

**In activist/movement contexts**: Pre-mortem surfaced early that a coalition was vulnerable to: leadership burnout from invisible emotional labor, a culture where white members didn't genuinely defer to BIPOC stewards despite saying they would, and a funding model that made smaller organizations dependent. Naming these as *imagined collapse* gave permission to design governance and sustainability differently from the start.

**In tech/product contexts**: Pre-mortems for AI products have surfaced: "Our model optimized for metrics but caused real harm to users who fell through the cracks," or "We shipped before understanding failure modes at scale." Working backward reveals: "We never built diverse adversarial testing into development," or "We have no robust feedback loop for users experiencing harm."

**Document patterns, not attribution.** Have someone (not leadership) record the failure chains that emerge. Not "Bob said the architecture would fail," but "Architectural brittleness risk: the system depends on undocumented tribal knowledge held by one engineer." This keeps the output diagnostic rather than political.

**Translate findings into present-day experiments or redesigns.** A pre-mortem that surfaces risks but doesn't change behavior is an expensive ritual. For each major causal chain identified, ask: "What small test, check, or structural change would we want to make *now* to reduce this risk?" Then commit to one or two, and track them.

---

### Section 5: Consequences

**What flourishes:**

Pre-mortem creates psychological permission for distributed intelligence to flow toward decision-making. The half-voiced concerns that experienced practitioners carry become explicit and workable. Team cohesion often strengthens paradoxically—people feel *heard* about their doubts, which reduces the silent erosion of trust that happens when concerns are suppressed.

The technique also surfaces systemic fragility before it becomes crisis. A commons that discovers early that it depends critically on one person's goodwill can redesign for resilience. An organization that learns its feedback loops are broken can rebuild them. This is genuine resilience-building—not eliminating risk (impossible), but surfacing and addressing the risks most likely to cascade.

In co-owned systems specifically, pre-mortem democratizes risk cognition. It says: "Your pattern recognition about failure matters. Your doubt is data." This sustains vitality by renewing the health of the stewardship culture itself.

**What risks emerge:**

**Routinization into hollow ritual**: If pre-mortem becomes an annual checkbox rather than a genuinely open inquiry, it calcifies. People deliver expected answers. The psychological safety erodes. The commons learns to pay lip service while continuing unchanged. Watch for: pre-mortems that generate long lists of risks that never actually get addressed, or sessions where the same risks surface year after year without design shifts.

**Defensive bifurcation**: Leadership can weaponize pre-mortem data. "We found these risks, so we're reducing autonomy to mitigate them." This violates the spirit of the practice. The technique depends on genuine commitment to *change based on findings*, not to accumulate justifications for control.

**Stagnation of adaptive capacity**: At 3.0 scores across resilience, ownership, and autonomy, this pattern sustains existing health but doesn't necessarily grow the commons' capacity to navigate *novel* failure modes. A pre-mortem can surface historical risks beautifully while missing genuinely unprecedented challenges. Pairs this with experimentation and distributed sense-making to avoid false confidence.

---

### Section 6: Known Uses

**Healthcare systems and surgical teams** pioneered the pre-mortem as an institutional practice. A surgical team imagines: "The patient suffered a complication we didn't anticipate." Working backward, they surface: "We never cross-checked the imaging," or "We assumed the anesthesiologist had the updated vitals." These become checklist items. The pattern is now embedded in safety protocols in high-stakes medical environments where failure is non-recoverable.

**The Movement for Black Lives** used pre-mortem in 2016 as coalitions were forming. Local organizers imagined: "The coalition collapsed. White-led organizations extracted knowledge and resources. BIPOC organizations were left holding the bag." Working backward, that surfaced: "We need explicit governance that names extractive dynamics *before* they happen," and "Resource flows need to move toward community leadership, not just toward visibility." Those backward-working insights shaped how several major coalitions designed their structures and funding.

**Spotify engineering teams** use pre-mortem in squad retrospectives, particularly for architectural decisions. A squad imagines: "We shipped and the system failed under load. Users churned. We had to revert." Working backward from that collapse, they surface: "We never actually tested with realistic data volume," or "We have a single point of failure in the caching layer." These become acceptance criteria that block PR merging until addressed. The technique is baked into their definition of "done."

**The Intergovernmental Panel on Climate Change (IPCC)** used pre-mortem thinking in designing its assessment processes. Researchers imagined: "Our assessments lost legitimacy and policymakers stopped using them." Working backward: "We never built adequate channels for indigenous knowledge," or "We created the appearance of certainty where uncertainty actually exists." This shaped how they restructured their working groups and how they frame uncertainty in reports.

---

### Section 7: Cognitive Era

In an age of machine learning and distributed intelligence systems, pre-mortem takes on new dimensions and new risks.

**New leverage**: AI systems surface patterns in data that humans miss—including failure modes. A pre-mortem can now be *informed* by anomaly detection: "Here are the stress points our ML models found most unstable under perturbation." This concentrates imagination on genuinely fragile spots rather than intuition alone. In product contexts, adversarial testing can generate failure scenarios at scale, which teams then use as input to pre-mortem: "Our model performed this way under this edge case—how did we get here?"

**New risks**: AI also accelerates the ability to rationalize away pre-mortem findings. If a model says "this risk is <2% probability," humans are highly susceptible to discounting it, even if the pre-mortem group flagged it as systemic. The quantitative confidence of algorithms can override the qualitative pattern recognition of distributed human intelligence. Practitioners must hold both—model confidence *and* human-experienced vulnerability signals.

**Composability becomes critical**: As systems become more interdependent, pre-mortems for single initiatives become insufficient. If your tech product integrates with five others, and each has their own failure modes, imagining your product's failure in isolation misses cascade risks. Practitioners need pre-mortems that explicitly model: "If *this* system fails, what cascades?" This requires shared failure scenarios across organizational boundaries.

**The governance question sharpens**: In a commons stewarded by both humans and algorithmic systems, who conducts the pre-mortem? Who has standing to say "I sense fragility"? If an ML system flags a risk but the team dismisses it, or vice versa, how do you resolve that in a way that honors both signal types? The pattern needs explicit governance about whose pattern recognition counts.

---

### Section 8: Vitality

**Signs of life:**

- After each pre-mortem, the team visibly changes something: a dependency is reduced, a communication channel is added, a hidden assumption is made explicit. Changes lag no more than one sprint/quarter.
- Participants report genuine surprise at what surfaced. ("I didn't realize we were all worried about the same thing.") This indicates real psychological safety and novel information flow, not recycled concerns.
- The initiative adapts its governance or design based on pre-mortem findings. A commons that surfaces "we're overreliant on one person's network" and then actually distributes that responsibility shows the pattern is alive.
- Follow-up: risks named in pre-mortem are tracked. "We said burnout risk was high. Did we reduce it? Did we fail to?" Accountability shows the pattern isn't theater.

**Signs of decay:**

- Pre-mortems surface the same risks every cycle, and nothing changes. The pattern has become ritual theater that *inoculates* against action ("we already know the risks") rather than generative.
- Participants become cautious or abstract in what they name. They avoid specificity because earlier feedback was ignored or weaponized. The psychological safety eroded.
- Leadership treats pre-mortem findings as useful input but doesn't redesign. Risks get acknowledged, then work continues unchanged. The pattern generates data but not adaptation.
- Pre-mortem sessions grow shorter, less attended, less engaged. The commons has learned it's optional, not structural.

**When to replant:**

If decay signs appear, stop running pre-mortems as scheduled. Instead, convene a smaller circle—stewards most invested in the commons's health—and ask: "What would need to be true for risk naming to actually change how we work?" This might surface that governance is blocked, that the initiative lacks authority to redesign, or that trust erosion has made the exercise unsafe. Address that first. Replant pre-mortem only once you've genuinely shifted what happens with the findings—otherwise you're just collecting data that erodes belief in the commons itself.
